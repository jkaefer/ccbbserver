{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pickle\n",
    "import joblib\n",
    "import sys\n",
    "sys.setrecursionlimit()\n",
    "#subprocess.call(['/home/pcuser/anaconda2/envs/py27/bin/python ~/Documents/regsnp_intron-master/regsnp_intron/predictor/predictor.py  /N/slate/jkaefer/introndb/model/ output/snp.features.txt output/snp.prediction'],shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/jkaefer/Carbonate/.conda/envs/newenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/N/u/jkaefer/Carbonate/.conda/envs/newenv/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/N/u/jkaefer/Carbonate/.conda/envs/newenv/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version pre-0.18 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/N/u/jkaefer/Carbonate/.conda/envs/newenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'max_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dba60d75f7d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/N/slate/jkaefer/introndb/model/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'on_ss_clf.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/newenv/lib/python3.6/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/newenv/lib/python3.6/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[0;32m~/.conda/envs/newenv/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/newenv/lib/python3.6/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mNDArrayWrapper\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \"\"\"\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mUnpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# For backward compatibility, we support NDArrayWrapper objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/newenv/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mload_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0msetstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__setstate__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msetstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m             \u001b[0msetstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0mslotstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'max_depth'"
     ]
    }
   ],
   "source": [
    "db='/N/slate/jkaefer/introndb/model/'\n",
    "joblib.load(db+'on_ss_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(object):\n",
    "    def __init__(self, on_ss_imp, off_ss_imp, on_ss_clf, off_ss_clf, on_ss_fpr_tpr, off_ss_fpr_tpr):\n",
    "        self.on_ss_imp = joblib.load(on_ss_imp)\n",
    "        self.off_ss_imp = joblib.load(off_ss_imp)\n",
    "        self.on_ss_clf = joblib.load(on_ss_clf)\n",
    "        self.off_ss_clf = joblib.load(off_ss_clf)\n",
    "        self.on_ss_fpr_tpr = pd.read_csv(on_ss_fpr_tpr, sep='\\t')\n",
    "        self.off_ss_fpr_tpr = pd.read_csv(off_ss_fpr_tpr, sep='\\t')\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def predict(self, ifname, ofname):\n",
    "        \"\"\"\n",
    "        Predict diseasing-causing probability of all intronic SNVs\n",
    "        :param ifname: m x n input file. m is the number of SNVs, n is the number of features.\n",
    "        :param ofname: output file prefix.\n",
    "        \"\"\"\n",
    "        self.logger.info('Loading all the features.')\n",
    "        data = pd.read_csv(ifname, sep='\\t', header=0)\n",
    "        data_on_ss = data[(data['distance'] >= -13) & (data['distance'] <= 7) & (data['distance'] != 0)]\n",
    "        data_off_ss = data[(data['distance'] < -13) | (data['distance'] > 7)]\n",
    "        if not data_on_ss.empty:\n",
    "            self.logger.info('Predicting on splicing site SNVs.')\n",
    "            preds, scores = self._predict_on_ss(data_on_ss)\n",
    "            fpr, tpr, disease = self._cal_fpr_tpr(scores, True)\n",
    "            data_on_ss.insert(4, 'splicing_site', ['on'] * len(preds))\n",
    "            data_on_ss.insert(4, 'fpr', fpr)\n",
    "            data_on_ss.insert(4, 'tpr', tpr)\n",
    "            data_on_ss.insert(4, 'prob', scores[:, 1])\n",
    "            data_on_ss.insert(4, 'disease', disease)\n",
    "        else:\n",
    "            data_on_ss.insert(4, 'splicing_site', '')\n",
    "            data_on_ss.insert(4, 'fpr', 0.0)\n",
    "            data_on_ss.insert(4, 'tpr', 0.0)\n",
    "            data_on_ss.insert(4, 'prob', 0.0)\n",
    "            data_on_ss.insert(4, 'disease', '')\n",
    "        if not data_off_ss.empty:\n",
    "            self.logger.info('Predicting off splicing site SNVs')\n",
    "            preds, scores = self._predict_off_ss(data_off_ss)\n",
    "            fpr, tpr, disease = self._cal_fpr_tpr(scores, False)\n",
    "            data_off_ss.insert(4, 'splicing_site', ['off'] * len(preds))\n",
    "            data_off_ss.insert(4, 'fpr', fpr)\n",
    "            data_off_ss.insert(4, 'tpr', tpr)\n",
    "            data_off_ss.insert(4, 'prob', scores[:, 1])\n",
    "            data_off_ss.insert(4, 'disease', disease)\n",
    "        else:\n",
    "            data_off_ss.insert(4, 'splicing_site', '')\n",
    "            data_off_ss.insert(4, 'fpr', 0.0)\n",
    "            data_off_ss.insert(4, 'tpr', 0.0)\n",
    "            data_off_ss.insert(4, 'prob', 0.0)\n",
    "            data_off_ss.insert(4, 'disease', '')\n",
    "        self.logger.info('Generate final output.')\n",
    "        result = pd.concat([data_on_ss, data_off_ss]).\\\n",
    "            sort_values(by=['#chrom', 'pos'])\n",
    "        result.to_csv(ofname + '.txt', sep='\\t', na_rep='NA', index=False)\n",
    "        records = result.loc[:, ['#chrom', 'pos', 'ref', 'alt', 'disease', 'prob', 'tpr', 'fpr', 'splicing_site', 'name', 'strand']].\\\n",
    "            to_dict(orient='records')\n",
    "        json.dump({\"data\": records}, open(ofname + '.json', 'w'))\n",
    "\n",
    "    def _predict_on_ss(self, data):\n",
    "        \"\"\"\n",
    "        Predict diseasing-causing probability of on-splicing-site SNVs\n",
    "        :param data: m x n pandas data frame. m is the number of SNVs, n is the number of features.\n",
    "        \"\"\"\n",
    "        data = data.drop(['#chrom', 'pos', 'ref', 'alt', 'name', 'strand', 'distance'], axis=1)\n",
    "        data = self.on_ss_imp.transform(data)\n",
    "        preds = self.on_ss_clf.predict(data)\n",
    "        scores = self.on_ss_clf.predict_proba(data)\n",
    "        return preds, scores\n",
    "\n",
    "    def _predict_off_ss(self, data):\n",
    "        \"\"\"\n",
    "        Predict diseasing-causing probability of off-splicing-site SNVs\n",
    "        :param data: m x n pandas data frame. m is the number of SNVs, n is the number of features.\n",
    "        \"\"\"\n",
    "        data = data.drop(['#chrom', 'pos', 'ref', 'alt', 'name', 'strand', 'distance', 'aic_change', 'dic_change'],\n",
    "                         axis=1)\n",
    "        data = self.off_ss_imp.transform(data)\n",
    "        preds = self.off_ss_clf.predict(data)\n",
    "        scores = self.off_ss_clf.predict_proba(data)\n",
    "        return preds, scores\n",
    "\n",
    "    def _cal_fpr_tpr(self, scores, on_ss):\n",
    "        \"\"\"\n",
    "\n",
    "        :param scores: predicted scores\n",
    "        :param on_ss: boolean indicate whether it's on_ss or off_ss\n",
    "        :return: fpr, tpr and disease\n",
    "        \"\"\"\n",
    "        fpr_tpr = None\n",
    "        if on_ss:\n",
    "            fpr_tpr = self.on_ss_fpr_tpr\n",
    "        else:\n",
    "            fpr_tpr = self.off_ss_fpr_tpr\n",
    "        fpr = [fpr_tpr.fpr[(abs(x - fpr_tpr.pvalue)).idxmin()] for x in scores[:,1]]\n",
    "        tpr = [fpr_tpr.tpr[(abs(x - fpr_tpr.pvalue)).idxmin()] for x in scores[:,1]]\n",
    "        cutoff = [0.0, 0.05, 0.1, 1.1]\n",
    "        disease_category = ['D', 'PD', 'B']\n",
    "        disease = np.digitize(fpr, cutoff)\n",
    "        disease = [disease_category[i - 1] for i in disease]\n",
    "        return fpr, tpr, disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db='/N/slate/jkaefer/introndb/model/'\n",
    "predictor = Predictor(db+'on_ss_imp.pkl',\n",
    "                      db+'off_ss_imp.pkl',\n",
    "                      db+'on_ss_clf.pkl',\n",
    "                      db+'off_ss_clf.pkl',\n",
    "                      db+'on_ss_fpr_tpr.txt',\n",
    "                      db+'off_ss_fpr_tpr.txt')\n",
    "predictor.predict('output/snp.features.txt','output/snp.prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
